{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import hvplot.pandas\n",
    "import panel as pn\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from panel.interact import interact\n",
    "from panel import widgets\n",
    "from string import digits\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import dateparser\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "debug_level = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions: TODO move to .py\n",
    "\n",
    "## Data cleaning\n",
    "def remove_strings_from_customer_names(original_customer_name):\n",
    "    invalid_strings = [\"PYMT\", \"DUE\"]\n",
    "    for invalid_item in invalid_strings:\n",
    "        original_customer_name = original_customer_name.replace(invalid_item, \"\")\n",
    "    return original_customer_name.strip()\n",
    "\n",
    "def remove_numbers_from_customer_names(original_customer_name):\n",
    "    remove_digits = str.maketrans('', '', digits) \n",
    "    return original_customer_name.translate(remove_digits).strip()  \n",
    "\n",
    "def cleanup_customer_names(paying_customers_raw):\n",
    "    paying_customers_cleanedup = []\n",
    "    for customer in paying_customers_raw:\n",
    "        corrected_customer_name = str(customer)\n",
    "        #corrected_customer_name = str(customer).upper()\n",
    "        corrected_customer_name = remove_strings_from_customer_names(corrected_customer_name)\n",
    "        corrected_customer_name = remove_numbers_from_customer_names(corrected_customer_name)\n",
    "        #corrected_customer_name = corrected_customer_name.title()\n",
    "        paying_customers_cleanedup.append(corrected_customer_name)\n",
    "    return paying_customers_cleanedup\n",
    "\n",
    "def build_name_mapping(paying_customers_cleanedup):\n",
    "    name_mapping = {}\n",
    "    n = 1\n",
    "    for customer in paying_customers_cleanedup:\n",
    "        if not customer in name_mapping:\n",
    "            name_mapping[customer] = \"University \" + str(n)\n",
    "            n += 1\n",
    "    return name_mapping\n",
    "\n",
    "def read_name_mapping():\n",
    "    with open(MAPPING_FILE_PATH, \"r\") as file:\n",
    "        return json.loads(file.read())\n",
    "\n",
    "def anonymize_customer_list(customer_list):\n",
    "    anonymized_customer_list = []\n",
    "    for customer in customer_list:\n",
    "        anonymized_customer_list.append(customer_name_mapping[customer])\n",
    "    return anonymized_customer_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants - TODO Move to .py\n",
    "MAPPING_DIR                     = Path(\"../Resources/Mappings\")\n",
    "DATA_DIR_RAW                    = Path(\"../Resources/01_Raw\")\n",
    "DATA_DIR_ANONYMIZED             = Path(\"../Resources/02_Anonymized\")\n",
    "DATA_DIR_PREPROCESSED           = Path(\"../Resources/03_Preprocessed\")\n",
    "DATA_DIR_PROCESSED              = Path(\"../Resources/04_Processed\")\n",
    "\n",
    "MAPPING_FILE_PATH               = os.path.join(MAPPING_DIR, Path(\"CustomerNameMapping.json\"))\n",
    "\n",
    "RAW_ATLAS_FILE_PATH             = os.path.join(DATA_DIR_RAW, Path(\"ATLAS.csv\"))\n",
    "RAW_FORECAST_DATA_FILE_PATH     = os.path.join(DATA_DIR_RAW, Path(\"2021 forecast CSV.csv\"))\n",
    "RAW_REVENUE2020_FILE_PATH       = os.path.join(DATA_DIR_RAW, Path(\"Revenue2020.csv\"))\n",
    "RAW_REVENUE2020A_FILE_PATH      = os.path.join(DATA_DIR_RAW, Path(\"Revenue2020A.csv\"))\n",
    "\n",
    "ANON_ATLAS_FILE_PATH            = os.path.join(DATA_DIR_ANONYMIZED, Path(\"ATLAS.csv\"))\n",
    "ANON_FORECAST_DATA_FILE_PATH    = os.path.join(DATA_DIR_ANONYMIZED, Path(\"2021 forecast CSV.csv\"))\n",
    "ANON_REVENUE2020_FILE_PATH      = os.path.join(DATA_DIR_ANONYMIZED, Path(\"Revenue2020.csv\"))\n",
    "ANON_REVENUE2020A_FILE_PATH     = os.path.join(DATA_DIR_ANONYMIZED, Path(\"Revenue2020A.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_date_string_list(date_string_list):\n",
    "    date_list = []\n",
    "    for date_string in date_string_list:\n",
    "        try:\n",
    "            date_list.append(parse_date_string(date_string))\n",
    "            #date_list.append( pd.Timestamp(date_string.replace(\"//\", \"/\"), tz=\"America/New_York\") )\n",
    "        except:\n",
    "            print(f\"Failed to parse: {date_string}\")\n",
    "    return date_list\n",
    "\n",
    "def cleanup_dollar_string(dollars_string):\n",
    "    return float(dollars_string.replace('$','').replace(',', ''))\n",
    "\n",
    "def cleanup_dollar_string_list(dollars_list_in):\n",
    "    dollars_list_out = []\n",
    "    for dollars_string in dollars_list_in:\n",
    "        try:\n",
    "            dollars_list_out.append( cleanup_dollar_string(dollars_string) )\n",
    "        except:\n",
    "            print(f\"Failed to parse: {dollars_string}\")\n",
    "    return dollars_list_out\n",
    "\n",
    "\n",
    "def extract_subscription_dates_list(subscription_dates_string_list):\n",
    "    \"\"\"\n",
    "    Parses a subscription date string from the ATLAS data export.\n",
    "\n",
    "    A sample is: \"1 Year Subscription 3/18/15 to 6/30/16\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subscription_dates_string_list: list[string]\n",
    "        List or iterable of strings in the ATLAS subscription date string format.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    [list, list]\n",
    "        List containing one list of start dates, followed by one list of end dates.\n",
    "    \"\"\"\n",
    "\n",
    "    subscription_dates_start_list = []\n",
    "    subscription_dates_end_list = []\n",
    "\n",
    "    for subscription_dates_string in subscription_dates_string_list:\n",
    "\n",
    "        # Split by \"Subscription\"\n",
    "        split1 = subscription_dates_string.find(\"Subscription\")\n",
    "        split2 = split1 + len(\"Subscription\")\n",
    "        date_range = subscription_dates_string[split2:].strip()\n",
    "\n",
    "        # Find split by \"to\"\n",
    "        split1 = date_range.find(\"to\")\n",
    "        split2 = split1 + len(\"to\")\n",
    "        if split1 < 0:\n",
    "            # Failed so split by \"-\"\n",
    "            split1 = date_range.find(\"-\")\n",
    "            split2 = split1 + len(\"-\")\n",
    "        \n",
    "        # Split\n",
    "        date1_str = date_range[0:split1].strip()\n",
    "        date2_str = date_range[split2:].strip()\n",
    "\n",
    "        # Parse dates\n",
    "        debug_level >= 2 and print(f\"date1_str: {date1_str}  date2_str: {date2_str}\")\n",
    "        date1 = parse_date_string(date1_str)\n",
    "        date2 = parse_date_string(date2_str)\n",
    "        debug_level >= 2 and print(f\"    date1_str: {date1_str}  date1: {date1}\")\n",
    "        debug_level >= 2 and print(f\"    date2_str: {date2_str}  date2: {date2}\")\n",
    "\n",
    "        # Build lists\n",
    "        subscription_dates_start_list.append(date1)\n",
    "        subscription_dates_end_list.append(date2)\n",
    "    \n",
    "    return [ subscription_dates_start_list, subscription_dates_end_list ]\n",
    "\n",
    "def parse_date_string(date_str):\n",
    "    date_str = date_str.replace(\"//\", \"/\")\n",
    "    try:\n",
    "        date = dateparser.parse(date_str)\n",
    "        return convert_datetime_to_timestamp(date)\n",
    "    except:\n",
    "        print(f\"Failed to parse: {date_str}\")\n",
    "        return \"\"\n",
    "\n",
    "def convert_datetime_to_timestamp(date_datetime):\n",
    "    return pd.Timestamp(date_datetime.isoformat(), tz=\"America/New_York\", tzinfo=date_datetime.tzinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "date1_str: 3/18/15  date2_str: 6/30/16\n    date1_str: 3/18/15  date1: 2015-03-18 00:00:00-04:00\n    date2_str: 6/30/16  date2: 2016-06-30 00:00:00-04:00\ndate1_str: 6/1/15  date2_str: 6/30/16\n    date1_str: 6/1/15  date1: 2015-06-01 00:00:00-04:00\n    date2_str: 6/30/16  date2: 2016-06-30 00:00:00-04:00\ndate1_str: 6/10/15  date2_str: 6/30/16\n    date1_str: 6/10/15  date1: 2015-06-10 00:00:00-04:00\n    date2_str: 6/30/16  date2: 2016-06-30 00:00:00-04:00\ndate1_str: 6/1/15  date2_str: 6/30/16\n    date1_str: 6/1/15  date1: 2015-06-01 00:00:00-04:00\n    date2_str: 6/30/16  date2: 2016-06-30 00:00:00-04:00\ndate1_str: 10/05/15  date2_str: 9/30/16\n    date1_str: 10/05/15  date1: 2015-10-05 00:00:00-04:00\n    date2_str: 9/30/16  date2: 2016-09-30 00:00:00-04:00\ndate1_str: 10/01/15  date2_str: 6/30/17\n    date1_str: 10/01/15  date1: 2015-10-01 00:00:00-04:00\n    date2_str: 6/30/17  date2: 2017-06-30 00:00:00-04:00\ndate1_str: 09/18/15  date2_str: 12/31/16\n    date1_str: 09/18/15  date1: 2015-09-18 00:00:00-04:00\n    date2_str: 12/31/16  date2: 2016-12-31 00:00:00-05:00\ndate1_str: 09/18/15  date2_str: 12/31/16\n    date1_str: 09/18/15  date1: 2015-09-18 00:00:00-04:00\n    date2_str: 12/31/16  date2: 2016-12-31 00:00:00-05:00\ndate1_str: 7/1/16  date2_str: 12/31/17\n    date1_str: 7/1/16  date1: 2016-07-01 00:00:00-04:00\n    date2_str: 12/31/17  date2: 2017-12-31 00:00:00-05:00\ndate1_str: 10/22/15  date2_str: 10/31/16\n    date1_str: 10/22/15  date1: 2015-10-22 00:00:00-04:00\n    date2_str: 10/31/16  date2: 2016-10-31 00:00:00-04:00\ndate1_str: 01/01/16  date2_str: 01/31/17\n    date1_str: 01/01/16  date1: 2016-01-01 00:00:00-05:00\n    date2_str: 01/31/17  date2: 2017-01-31 00:00:00-05:00\ndate1_str: 01/01/16  date2_str: 01/31/17\n    date1_str: 01/01/16  date1: 2016-01-01 00:00:00-05:00\n    date2_str: 01/31/17  date2: 2017-01-31 00:00:00-05:00\ndate1_str: 01/07/16  date2_str: 01/31/17\n    date1_str: 01/07/16  date1: 2016-01-07 00:00:00-05:00\n    date2_str: 01/31/17  date2: 2017-01-31 00:00:00-05:00\ndate1_str: 1/7/18  date2_str: 1/31/19\n    date1_str: 1/7/18  date1: 2018-01-07 00:00:00-05:00\n    date2_str: 1/31/19  date2: 2019-01-31 00:00:00-05:00\ndate1_str: 1/7/17  date2_str: 1/31/18\n    date1_str: 1/7/17  date1: 2017-01-07 00:00:00-05:00\n    date2_str: 1/31/18  date2: 2018-01-31 00:00:00-05:00\ndate1_str: 01/06/16  date2_str: 06/30/17\n    date1_str: 01/06/16  date1: 2016-01-06 00:00:00-05:00\n    date2_str: 06/30/17  date2: 2017-06-30 00:00:00-04:00\ndate1_str: 01/19/16  date2_str: January 31,2017\n    date1_str: 01/19/16  date1: 2016-01-19 00:00:00-05:00\n    date2_str: January 31,2017  date2: 2017-01-31 00:00:00-05:00\ndate1_str: 01/19/16  date2_str: January 31,2017\n    date1_str: 01/19/16  date1: 2016-01-19 00:00:00-05:00\n    date2_str: January 31,2017  date2: 2017-01-31 00:00:00-05:00\ndate1_str: 02/15/16  date2_str: 06/30/2017\n    date1_str: 02/15/16  date1: 2016-02-15 00:00:00-05:00\n    date2_str: 06/30/2017  date2: 2017-06-30 00:00:00-04:00\ndate1_str: 06/30/16  date2_str: 06/30/17\n    date1_str: 06/30/16  date1: 2016-06-30 00:00:00-04:00\n    date2_str: 06/30/17  date2: 2017-06-30 00:00:00-04:00\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[Timestamp('2015-03-18 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2015-06-01 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2015-06-10 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2015-06-01 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2015-10-05 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2015-10-01 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2015-09-18 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2015-09-18 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2016-07-01 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2015-10-22 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2016-01-01 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2016-01-01 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2016-01-07 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2018-01-07 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2017-01-07 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2016-01-06 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2016-01-19 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2016-01-19 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2016-02-15 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2016-06-30 00:00:00-0400', tz='America/New_York')],\n",
       " [Timestamp('2016-06-30 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2016-06-30 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2016-06-30 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2016-06-30 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2016-09-30 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2017-06-30 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2016-12-31 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2016-12-31 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2017-12-31 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2016-10-31 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2017-01-31 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2017-01-31 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2017-01-31 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2019-01-31 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2018-01-31 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2017-06-30 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2017-01-31 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2017-01-31 00:00:00-0500', tz='America/New_York'),\n",
       "  Timestamp('2017-06-30 00:00:00-0400', tz='America/New_York'),\n",
       "  Timestamp('2017-06-30 00:00:00-0400', tz='America/New_York')]]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# import dateparser\n",
    "# date1 = dateparser.parse('12/12/12')\n",
    "# date1 = dateparser.parse('January 31,2017')\n",
    "# date2 = pd.Timestamp(date1.isoformat(), tz=\"America/New_York\", tzinfo=date.tzinfo)\n",
    "# date2\n",
    "# type(date2)\n",
    "extract_subscription_dates_list(atlas.iloc[0:20][\"Dates of service \"])\n",
    "# atlas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read anonymized data\n",
    "atlas           = pd.read_csv(ANON_ATLAS_FILE_PATH, index_col=\"Customers\")\n",
    "forecast        = pd.read_csv(ANON_FORECAST_DATA_FILE_PATH, index_col=\"Organization Name\")\n",
    "revenue2020     = pd.read_csv(ANON_REVENUE2020_FILE_PATH, index_col=\"Name\")\n",
    "revenue2020A    = pd.read_csv(ANON_REVENUE2020A_FILE_PATH, index_col=\"Payee Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               Invoice Date  Invoice #  Invoice Amount Subscription  \\\n",
       "Customers                                                             \n",
       "University 1     2015-03-20  ATLAS 315         72000.0       1 Year   \n",
       "University 102   2015-05-28      AJ501          3500.0       1 Year   \n",
       "University 3     2015-06-23      AJ502          3500.0       1 Year   \n",
       "University 4     2015-06-26      AJ503          6500.0       1 Year   \n",
       "University 5     2015-10-07      AJ504           750.0       1 Year   \n",
       "\n",
       "                          Account Code   \\\n",
       "Customers                                 \n",
       "University 1    4700-0-00-00000-18-0000   \n",
       "University 102  4700-0-00-00000-16-0000   \n",
       "University 3    4700-0-00-00000-17-0000   \n",
       "University 4    4700-0-00-00000-32-0000   \n",
       "University 5    4700-0-00-00000-20-0000   \n",
       "\n",
       "                                      Dates of service   \n",
       "Customers                                                \n",
       "University 1     1 Year Subscription 3/18/15 to 6/30/16  \n",
       "University 102    1 Year Subscription 6/1/15 to 6/30/16  \n",
       "University 3     1 Year Subscription 6/10/15 to 6/30/16  \n",
       "University 4      1 Year Subscription 6/1/15 to 6/30/16  \n",
       "University 5    1 Year Subscription 10/05/15 to 9/30/16  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Invoice Date</th>\n      <th>Invoice #</th>\n      <th>Invoice Amount</th>\n      <th>Subscription</th>\n      <th>Account Code</th>\n      <th>Dates of service</th>\n    </tr>\n    <tr>\n      <th>Customers</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>University 1</th>\n      <td>2015-03-20</td>\n      <td>ATLAS 315</td>\n      <td>72000.0</td>\n      <td>1 Year</td>\n      <td>4700-0-00-00000-18-0000</td>\n      <td>1 Year Subscription 3/18/15 to 6/30/16</td>\n    </tr>\n    <tr>\n      <th>University 102</th>\n      <td>2015-05-28</td>\n      <td>AJ501</td>\n      <td>3500.0</td>\n      <td>1 Year</td>\n      <td>4700-0-00-00000-16-0000</td>\n      <td>1 Year Subscription 6/1/15 to 6/30/16</td>\n    </tr>\n    <tr>\n      <th>University 3</th>\n      <td>2015-06-23</td>\n      <td>AJ502</td>\n      <td>3500.0</td>\n      <td>1 Year</td>\n      <td>4700-0-00-00000-17-0000</td>\n      <td>1 Year Subscription 6/10/15 to 6/30/16</td>\n    </tr>\n    <tr>\n      <th>University 4</th>\n      <td>2015-06-26</td>\n      <td>AJ503</td>\n      <td>6500.0</td>\n      <td>1 Year</td>\n      <td>4700-0-00-00000-32-0000</td>\n      <td>1 Year Subscription 6/1/15 to 6/30/16</td>\n    </tr>\n    <tr>\n      <th>University 5</th>\n      <td>2015-10-07</td>\n      <td>AJ504</td>\n      <td>750.0</td>\n      <td>1 Year</td>\n      <td>4700-0-00-00000-20-0000</td>\n      <td>1 Year Subscription 10/05/15 to 9/30/16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Clean up ATLAS data\n",
    "atlas[\"Invoice Date\"]       = cleanup_date_string_list(atlas[\"Invoice Date\"])\n",
    "atlas[\"Invoice Amount\"]     = cleanup_dollar_string_list(atlas[\"Invoice Amount\"])\n",
    "# atlas[\"Service Start\"]      = extract_subscription_dates_start_list(atlas[\"Dates of service\"])\n",
    "# atlas[\"Service End\"]        = extract_subscription_dates_end_list(atlas[\"Dates of service\"])\n",
    "# atlas.drop(columns=[\"Dates of service\"], inplace=True)\n",
    "atlas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('pyvizenv': conda)",
   "display_name": "Python 3.8.3 64-bit ('pyvizenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9b71b9fa21544dd8a39d3650f5526997ede89e0b97dc642fc8071b919dea00e5"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}